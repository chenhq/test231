{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load params_select.py\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import seaborn as snb\n",
    "from hyperopt import hp\n",
    "from keras.initializers import glorot_uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "from data_prepare import *\n",
    "from index_components import zz500_t10\n",
    "from objective import objective\n",
    "from trial import run_a_trial\n",
    "\n",
    "snb.set()\n",
    "from loss import *\n",
    "\n",
    "try:\n",
    "    import _pickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "identity = 'caosg4'\n",
    "\n",
    "lstm_space = {\n",
    "    'time_steps': hp.choice('time_steps', [64]),\n",
    "    'batch_size': hp.choice('batch_size', [64]),\n",
    "    'epochs': hp.choice('epochs', [500]),  # [100, 200, 500, 1000, 1500, 2000]\n",
    "\n",
    "    # for class\n",
    "    'activation_last': hp.choice('activation_last', ['softmax']),\n",
    "    # for regression\n",
    "    # 'activation_last': hp.choice('activation', [None, 'linear']),\n",
    "\n",
    "    #\n",
    "    'shuffle': hp.choice('shuffle', [False]),\n",
    "    'loss_type': hp.choice('loss', ['categorical_crossentropy']), #, 'weighted_categorical_crossentropy']),\n",
    "\n",
    "    'layer1': {\n",
    "        'units': hp.choice('layer1_units', [128]),\n",
    "        # 'relu', 'sigmoid', 'tanh', 'linear'\n",
    "        'activation': hp.choice('layer1_activation', ['tanh']),\n",
    "        'is_BN': hp.choice('layer1_is_BN', [True]),\n",
    "    },\n",
    "    'layer2': {\n",
    "        'units': hp.choice('layer2_units', [128]),\n",
    "        # 'relu', 'sigmoid', 'tanh', 'linear'\n",
    "        'activation': hp.choice('layer2_activation', ['tanh']),\n",
    "        'is_BN': hp.choice('layer2_is_BN', [True]),\n",
    "    },\n",
    "    'layer3': {\n",
    "        'units': hp.choice('layer3_units', [128]),\n",
    "        # 'relu', 'sigmoid', 'tanh', 'linear'\n",
    "        # Loss turns into 'nan'\n",
    "        # As far as I know, it's the combination of relu and softmax that causes numerical troubles,\n",
    "        # as relu can produce large positive values corresponding to very small probabilities.\n",
    "        # If you change your model to use, say, tanh instead of relu for the last dense layer,\n",
    "        # the problem will go away.\n",
    "        'activation': hp.choice('layer3_activation', ['tanh']),\n",
    "        'is_BN': hp.choice('layer3_is_BN', [True]),\n",
    "    },\n",
    "\n",
    "    # 'lr': hp.loguniform('lr', np.log(0.000001), np.log(0.0001)),\n",
    "    'lr': hp.choice('lr', [0.0001]),\n",
    "    'dropout': hp.quniform('dropout', 0.3, 0.31, 0.1),\n",
    "    'recurrent_dropout': hp.quniform('recurrent_dropout', 0.3, 0.31, 0.1),\n",
    "    'kernel_initializer': hp.choice('kernel_initializer', [glorot_uniform(seed=123)]),\n",
    "    'bias_initializer': hp.choice('bias_initializer', [glorot_uniform(seed=456)]),\n",
    "}\n",
    "\n",
    "# kline2_params = {\n",
    "#     'window': 256,\n",
    "# }\n",
    "# params_list.append(kline2_params)\n",
    "# func_list.append(feature_kline2)\n",
    "#\n",
    "# label_by_multi_ma_params = {\n",
    "#     'window': [3, 5, 10]\n",
    "# }\n",
    "# params_list.append(label_by_multi_ma_params)\n",
    "# func_list.append(label_by_multi_ma)\n",
    "\n",
    "features_space = {\n",
    "    # 'kline': {\n",
    "    #     'window': hp.choice('kline_window', [[60]])\n",
    "    # },\n",
    "    'kline2': {\n",
    "        'window': hp.choice('kline2_window', [256])\n",
    "    },\n",
    "    # 'ma': {\n",
    "    #     'ma_list': hp.choice('ma_list', [[1, 2, 3, 5, 8, 13, 21]]),\n",
    "    #     'window': hp.choice('ma_window', [[60]]),\n",
    "    #     'price': hp.choice('price', ['close'])\n",
    "    # },\n",
    "    # 'label_by_ma_price': {\n",
    "    #     'window': hp.choice('label_window', [60]),\n",
    "    #     'next_ma_window': hp.choice('next_ma_window', [3]),\n",
    "    #     'quantile_list': hp.choice('quantile_list', [# [0, 0.1, 0.3, 0.7, 0.9, 1],\n",
    "    #                                                  # [0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "    #                                                  # [0, 0.15, 0.3, 0.7, 0.85, 1],\n",
    "    #                                                  # [0, 0.15, 0.35, 0.65, 0.85, 1],\n",
    "    #                                                  # [0, 0.3, 0.7, 1],\n",
    "    #                                                  [0, 0.33, 0.66, 1],\n",
    "    #                                                  # [0, 0.2, 0.8, 1],\n",
    "    #                                                  # [0, 0.4, 0.6, 1],\n",
    "    #                                                  # [0, 0.5, 1],\n",
    "    #                                                  # [0, 0.45, 1],\n",
    "    #                                                  # [0, 0.55, 1]\n",
    "    #                                                 ])\n",
    "    # },\n",
    "    'label_by_multi_ma': {\n",
    "        'window': hp.choice('label_window', [[3, 5, 10]])\n",
    "    },\n",
    "    'label': {\n",
    "        'class_list': hp.choice('class_list', [[0.0, 1.0]])\n",
    "    }\n",
    "}\n",
    "\n",
    "space = {\n",
    "    'features': features_space,\n",
    "    'lstm': lstm_space,\n",
    "    'split_dates': [\"2016-01-01\", \"2017-01-01\"]\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # file_name = '../data/cs_market.csv'\n",
    "    # ohlcv_list = get_data(file_name=file_name, stks=zz500_t10)\n",
    "\n",
    "    # zz500 = pickle.load(open('data/zz500.pkl', 'rb'))\n",
    "    # ohlcv_list = [zz500]\n",
    "\n",
    "    pickle_file = 'data/sz50_ohlcv.pkl'\n",
    "    ohlcv_list = get_pickle_data(pickle_file, [])\n",
    "\n",
    "    function = \"params_select\"\n",
    "    if identity == \"\":\n",
    "        identity = str(uuid.uuid1())\n",
    "\n",
    "    print(\"identity: {}\".format(identity))\n",
    "    namespace = function + '_' + identity\n",
    "\n",
    "    namespace = os.path.join('./', namespace)\n",
    "    if not os.path.exists(namespace):\n",
    "        os.makedirs(namespace)\n",
    "\n",
    "    with open(os.path.join(namespace, 'ohlcv_list.pkl'), 'wb') as f:\n",
    "        pickle.dump(ohlcv_list, f)\n",
    "\n",
    "    # # loss\n",
    "    # loss = 'categorical_crossentropy'\n",
    "    # loss = weighted_categorical_crossentropy5\n",
    "    objective_func = partial(objective, ohlcv_list=ohlcv_list, namespace=namespace)\n",
    "\n",
    "    trials_file = os.path.join(namespace, 'trials.pkl')\n",
    "\n",
    "    # while True:\n",
    "    run_a_trial(trials_file, objective_func, space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
